1. Синхронное взаимодействие в рамках Java Spring
2. Гарантии доставки сообщений
3. Timeout, Rate Limiter, Circuit Breaker
---
# Синхронное взаимодействие в рамках Java Spring

## Введение  
Синхронное взаимодействие является одним из ключевых аспектов при проектировании сервисно-ориентированной архитектуры на Java Spring. В рамках данной лекции мы рассмотрим:  
  
- Что такое синхронное взаимодействие.  
- Как реализовать синхронные вызовы в Spring.  
- Использование HTTP и REST API.  
- Управление потоками и конкурентным выполнением.  
- Проблемы синхронного взаимодействия и их решения.  
- Лучшие практики и рекомендации по построению эффективных синхронных сервисов.    
---  
## Что такое синхронное взаимодействие?  
  
Синхронное взаимодействие означает, что клиент отправляет запрос и ожидает ответ от сервера. Пока запрос не будет обработан, клиент не может продолжить выполнение.  
  
### Пример взаимодействия:  
  
	Client → [HTTP Request] → Server  
	Client ← [HTTP Response] ←  Server

### Поток данных
```  
HTTP Request → DispatcherServlet → Controller → Service → DAO → DB  
HTTP Response ← ViewResolver ← Controller ← Service ← DAO ← DB  
```  
  
Преимущества:
- Простота реализации и отладки.  
- Поддержка транзакционности.  
- Хорошая совместимость с существующими HTTP API. 
Недостатки:
- Высокая латентность при медленных запросах.  
- Блокировка потоков, что снижает производительность.  
- Проблемы масштабируемости при высокой нагрузке.  

### Типичные блокирующие операции
- Доступ к БД(JDBC, JPA).  
- Внешние HTTP-вызовы (REST-клиенты).  
- Файловые операции (чтение/запись).  

---  
## Синхронная обработка HTTP-запросов в Spring MVC <a name="синхронная-обработка-http-запросов-в-spring-mvc"></a>  
  
В Spring MVC по умолчанию используется синхронная модель обработки запросов. Каждый HTTP-запрос обрабатывается отдельным потоком из пула сервлетов, который блокируется до завершения обработки.  
  
### Жизненный цикл запроса
1. Клиент отправляет HTTP-запрос.  
2. Сервер (например, Tomcat) выделяет поток из пула для обработки.  
3. Поток передаётся в `DispatcherServlet` — центральный контроллер Spring MVC.  
4. `DispatcherServlet` определяет подходящий контроллер и вызывает его метод.  
5. Метод контроллера выполняет бизнес-логику (возможно, с блокирующими операциями).  
6. Результат возвращается клиенту, и поток освобождается.  

## Реализация синхронного взаимодействия в Spring  
### Создание REST-контроллера  
  
Простейший контроллер в Spring Boot, обрабатывающий HTTP-запросы:  
  
```java
@RestController  
@RequestMapping("/api")  
public class SyncController {  
	@GetMapping("/sync")  
	public ResponseEntity<String> getSyncResponse() {  
	    return ResponseEntity.ok("Hello from Sync API");  
	}  
}  
```
  
### Вызов API с помощью RestTemplate  
  
```java
@RestController  
@RequestMapping("/client")  
public class RestClient {  
	private final RestTemplate restTemplate = new RestTemplate();  
	  
	@GetMapping("/call")  
	public String callApi() {  
		String response = restTemplate.getForObject("http://localhost:8080/api/sync", String.class);  
		return "Received: " + response;  
	}  
}  
```
  
###  Вызов API с помощью WebClient  
  
```java
@RestController  
@RequestMapping("/client")  
public class WebClientController {  
	private final WebClient webClient = WebClient.create();  
	  
	@GetMapping("/call")  
	public String callApi() {  
		return webClient.get()  
		.uri("http://localhost:8080/api/sync")  
		.retrieve()  
		.bodyToMono(String.class)  
		.block();  
	}  
}  
```
    
### Методы HTTP и их использование  
  
HTTP-методы:  
- GET – получение данных.  
- POST – отправка новых данных.  
- PUT – обновление всех данных модели
- PATCH - обновление части данных модели
- DELETE – удаление данных.  
  
Пример обработки разных методов в Spring:  
```java
@RestController  
@RequestMapping("/resource")  
public class ResourceController {  
	@PostMapping  
	public ResponseEntity<String> create(@RequestBody String body) {  
	    return ResponseEntity.status(HttpStatus.CREATED).body("Resource created: " + body);  
}  
  
	@PutMapping("/{id}")  
	public ResponseEntity<String> update(@PathVariable String id, @RequestBody String body) {  
	    return ResponseEntity.ok("Resource " + id + " updated to: " + body);  
	}  
  
	@DeleteMapping("/{id}")  
	public ResponseEntity<String> delete(@PathVariable String id) {  
	    return ResponseEntity.ok("Resource " + id + " deleted");  
	}  
}  
```

### Управление потоками и конкурентное выполнение  
  
```java
@Service  
public class SyncService {  
	private final ExecutorService executorService = Executors.newFixedThreadPool(10);  
	  
	public Future<String> processRequest() {  
		return executorService.submit(() -> {  
			Thread.sleep(1000);  
			return "Processed result";  
	    });  
	}  
}  
```
  
### Проблемы и их решения     
#### 1. Проблема высокой латентности  
  
Решение: Использование кэширования (Spring Cache):  
  
```java
@Cacheable("responses")  
public String getCachedResponse() {  
    return "Cached data";  
}  
```
  
#### 2. Проблема отказов при взаимодействии  
  
Решение: Использование Circuit Breaker (Resilience4j):  
  
```java
@CircuitBreaker(name = "syncService", fallbackMethod = "fallback")  
public String callExternalService() {  
	return restTemplate.getForObject("http://unreliable-service/api", String.class);  
}

public String fallback(Exception e) {  
    return "Fallback response";  
}  
```
  
#### 3. Проблема таймаутов HTTP-запросов

Решение: настроить таймауты для каждого клиента/внешнего сервиса
  
```java
@Bean  
public RestTemplate restTemplate() {  
	SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();  
	factory.setConnectTimeout(5000);  
	factory.setReadTimeout(5000);  
	
	return new RestTemplate(factory);  
}  
```

### Общие проблемы синхронной модели 
1. **Блокировка потоков**: Поток сервера занят, пока запрос не завершится.  
2. **Ограниченная масштабируемость**: Число одновременных запросов зависит от размера пула потоков.  
3. **Риск исчерпания ресурсов**: Долгие запросы (например, сложные вычисления) могут заблокировать все потоки.  
  
### Настройка пула потоков в Spring Boot
По умолчанию встроенные серверы (Tomcat) используют пул потоков с параметрами:  
```properties
	server.tomcat.threads.max=200
	server.tomcat.threads.min=10  
```
### Лучшие практики  

- Минимизируйте использование блокирующих вызовов.  
- Настраивайте таймауты.  
- Используйте балансировщики нагрузки.  
- Используйте **кеширование** (Spring Cache) для снижения нагрузки на БД.  
- Оптимизируйте SQL-запросы и индексы.  
- Для долгих операций рассмотрите асинхронную обработку (`@Async`).  

### Рекомендации по использованию <a name="рекомендации-по-использованию"></a> 
#### Когда использовать синхронную обработку
1. **Прототипирование**: Быстрая разработка MVP.  
2. **CRUD-приложения**: Невысокая нагрузка, простые операции.  
#### Когда переходить на асинхронную обработку
1. **Высокая нагрузка**: Тысячи одновременных запросов.  
2. **Долгие операции**: Обработка файлов, интеграция с внешними API.  

### Заключение  
  
Синхронное взаимодействие в Spring Boot реализуется через:  
- REST API с RestTemplate и WebClient.  
- Механизмы потоков и асинхронности для повышения эффективности.  
- HTTP-клиенты с настройками таймаутов и отказоустойчивости.  
- Паттерны архитектуры- вручную или через внешние библиотеки

Синхронная обработка HTTP-запросов в Spring — это стандартный подход, идеально подходящий для большинства веб-приложений. Она проста в реализации, но требует внимания к производительности при работе с блокирующими операциями. Используйте пулы потоков, кеширование и оптимизацию запросов, чтобы избежать узких мест. Для высоконагруженных систем или долгих задач рассмотрите асинхронные решения, такие как Spring WebFlux.

---
# Гарантии доставки сообщений в рамках Java Spring HTTP  
  
## Введение  
  
В современных распределенных системах важно обеспечивать надежную передачу сообщений между клиентами и сервисами. В рамках Java Spring HTTP можно реализовать различные механизмы гарантированной доставки сообщений, используя встроенные инструменты Spring, а также интеграцию с брокерами сообщений и базами данных.  

---  
  
## Уровни гарантий доставки сообщений  
  
### 1. At Most Once (Не более одного раза)  
  
Данный уровень гарантирует, что сообщение будет отправлено не более одного раза, но оно может быть потеряно. Такой подход используется, если не критично, что часть сообщений не дойдет.  
  
Пример реализации контроллера с At Most Once:  
  
```java
@RestController  
@RequestMapping("/api")  
public class AtMostOnceController {  
	@PostMapping("/process")  
	public ResponseEntity<String> process(@RequestBody String data) {  
	    return ResponseEntity.ok("Processed: " + data);  
	}  
}  
```
  
Здесь, если сеть оборвется или сервер упадет после отправки ответа, клиент не будет знать о потере сообщения.  
  
### 2. At Least Once (Не менее одного раза)  
  
Этот уровень гарантирует, что сообщение будет доставлено хотя бы один раз, но возможны дубликаты. Это достигается с помощью механизма повторных попыток (retry).  
  
Пример с Spring Retry:  
```java
@Service  
public class ReliableService {  
	@Retryable(value = RuntimeException.class, maxAttempts = 3, backoff = @Backoff(delay = 2000))  
	public String process(String data) {  
		if (Math.random() > 0.5) {  
		    throw new RuntimeException("Temporary failure");  
		}  
		return "Processed: " + data;  
	}  
}  
```
  
В этом примере, если метод выбрасывает исключение, Spring автоматически повторит вызов до 3 раз.  

### 3. Exactly Once (Ровно один раз)  
  
Гарантирует, что сообщение будет доставлено ровно один раз. Достигается за счет идемпотентности и транзакционных механизмов.  
  
Пример использования уникальных идентификаторов:  
  
```java
@Service  
public class IdempotentService {  
	private final Set<String> processedIds = ConcurrentHashMap.newKeySet();  
	  
	public String process(String id, String data) {  
		if (!processedIds.add(id)) {  
			return "Already processed";  
		}  
		return "Processed: " + data;  
	}  
}  
```
  
Этот подход предотвращает повторную обработку уже полученных сообщений.  

### Dead Letter Queue (DLQ)  

***Обычно относится к системам очередей- Kafka и RabbitMQ, но по такому же принципу можно организовать обработку запросов и в своём коде.***

Очередь недоставленных писем (DLQ) – это особый тип очереди, где временно хранятся сообщения, которые программная система не может обработать из-за ошибок. Очереди сообщений – это программные компоненты, поддерживающие асинхронное взаимодействие в распределенной системе. Они обеспечивают обмен сообщениями между программными службами в любом объеме и не требуют постоянной доступности получателя сообщений. В очереди недоставленных писем специально хранятся ошибочные сообщения, которые не имеют адресата или не могут быть обработаны предполагаемым получателем.

Очереди недоставленных писем (DLQ) существуют наряду с обычными очередями сообщений. Они служат временным хранилищем сообщений с ошибками и сбоями. DLQ предотвращают переполнение исходной очереди необработанными сообщениями.

Например, рассмотрим программное обеспечение с обычной очередью сообщений и DLQ. Программное обеспечение использует обычную очередь для хранения сообщений, которые оно планирует отправить получателю. Если получатель не отвечает на отправленные сообщения или не обрабатывает их, программное обеспечение перемещает их в очередь незавершенных писем.

Когда следует использовать очередь недоставленных писем:
- Если в системе возникли следующие проблемы, можно использовать очередь недоставленных писем (DLQ). 
- Неупорядоченные очереди
Вы можете воспользоваться преимуществами DLQ, когда порядок сообщения не важен. Хотя DLQ помогают устранять некорректные операции передачи сообщений, вам следует продолжать отслеживать очереди и повторно отправлять неудачные сообщения. 
- Очереди FIFO
Упорядочивание сообщений важно в очередях по принципу «первым получено – первым отправлено» (FIFO). Каждое сообщение должно быть обработано перед отправкой следующего сообщения. В очередях FIFO можно использовать очереди с неработающими письмами, но ваше решение DLQ также должно быть реализовано по модели FIFO.

В каких случаях не следует использовать очередь недоставленных писем:

- Не следует использовать очередь недоставленных писем (DLQ) с неупорядоченными очередями, если вы хотите бесконечно повторять попытку передачи сообщения. Например, не используйте очередь недоставленных писем, если вашей программе приходится ждать, когда зависимый процесс станет активным или доступным. 
- Точно так же не следует использовать очередь недоставленных писем с очередью «первым получено – первым отправлено» (FIFO), если вы не хотите нарушать точный порядок сообщений или операций. Например, не используйте очередь недоставленных писем с инструкциями в списке решений по редактированию (EDL) для пакета для редактирования видео. В этом случае, изменяя порядок правок, вы изменяете контекст последующих правок.

### Заключение  
  
Гарантии доставки сообщений в Spring обеспечиваются через:  

- HTTP-ответы и повторные попытки (@Retryable).  
- Транзакции (@Transactional).  
- Использование брокеров сообщений (RabbitMQ, Kafka).  

  
Выбор подходящего механизма зависит от требований системы. Использование комбинации этих инструментов позволяет добиться высокой надежности передачи сообщений.  

---

# Паттерны Rate Limiter и Circuit Breaker в рамках java Spring  
  
## Введение  
  
При проектировании надежных и масштабируемых распределенных систем важно учитывать ограничения нагрузки и отказоустойчивость сервисов. Два ключевых паттерна, которые помогают справляться с этими проблемами, — Rate Limiter (Ограничитель запросов) и Circuit Breaker (Предохранитель). В данной лекции мы рассмотрим, как они работают, какие инструменты предоставляет Spring для их реализации, и разберем примеры кода.  
  
---  
  
## Паттерн Rate Limiter (Ограничитель запросов)  
  
### Что такое Rate Limiter?  
  
Rate Limiter ограничивает количество запросов, обрабатываемых сервисом за определенный промежуток времени. Это помогает предотвратить перегрузку системы и защитить от DDoS-атак.  

Основные стратегии:
- Fixed Window (Фиксированное окно) — устанавливается жесткий лимит запросов на фиксированный период времени.  
- Sliding Window (Скользящее окно) — запросы анализируются в скользящем временном диапазоне.  
- Token Bucket (Ведро с токенами) — пользователи получают токены, которые позволяют делать запросы.  
- Leaky Bucket (Протекающее ведро) — запросы обрабатываются с фиксированной скоростью.  
  
### Реализация Rate Limiter в Spring Boot  
  
Spring Boot поддерживает ограничение запросов с помощью библиотеки Resilience4j.  
  
Подключение зависимости  
  
```xml
<dependency>  
	<groupId>io.github.resilience4j</groupId>  
	<artifactId>resilience4j-ratelimiter</artifactId>  
	<version>1.7.1</version>  
</dependency>  
```
  
Конфигурация Rate Limiter  
  
```yaml
resilience4j.ratelimiter:  
	instances:  
		apiRateLimiter:  
			limit-for-period: 5  
			limit-refresh-period: 10s  
			timeout-duration: 0  
```
  
Применение к методу контроллера  
  
```java
@RestController  
@RequestMapping("/api")  
public class RateLimitedController {  
  
	private final RateLimiter rateLimiter = RateLimiter.ofDefaults("apiRateLimiter");  
	  
	@GetMapping("/limited")  
	public String limitedEndpoint() {  
		return rateLimiter.executeSupplier(() -> "Request processed");  
	}  
}  
```
  
В этом примере контроллер принимает не более 5 запросов в 10 секунд.  
  
## Паттерн Circuit Breaker (Предохранитель)  
  
Circuit Breaker предотвращает каскадные отказы в распределенных системах. Если сервис начинает работать нестабильно (например, медленно отвечает или падает), предохранитель временно блокирует вызовы к нему.  
  
Основные состояния:
- Closed (Закрытое) — все запросы проходят.  
- Open (Открытое) — все запросы блокируются.  
- Half-Open (Полуоткрытое) — часть запросов проходит для проверки восстановления сервиса.  
  
  
### Реализация Circuit Breaker в Spring Boot  
  
Для управления отказами удобно использовать Resilience4j.  
  
Подключение зависимости  
  
```xml
<dependency>  
	<groupId>io.github.resilience4j</groupId>  
	<artifactId>resilience4j-circuitbreaker</artifactId>  
	<version>1.7.1</version>  
</dependency>  
```
  
Конфигурация Circuit Breaker  
  
```yaml
resilience4j.circuitbreaker:  
	instances:  
		apiCircuitBreaker:  
			failure-rate-threshold: 50  
			wait-duration-in-open-state: 10s  
			permitted-number-of-calls-in-half-open-state: 3  
			sliding-window-type: count_based  
			sliding-window-size: 10  
```
  
Применение к методу контроллера  
  
```java
@RestController  
@RequestMapping("/api")  
public class CircuitBreakerController {  
  
	private final CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults("apiCircuitBreaker");  
	  
	@GetMapping("/unstable")  
	public String unstableEndpoint() {  
		return circuitBreaker.executeSupplier(() -> {  
			if (Math.random() > 0.5) {  
				throw new RuntimeException("Service failure");  
			}  
			return "Request successful";  
		});  
	}  
}  
```
  
В этом примере, если 50% запросов завершаются с ошибкой, сервис временно блокируется.  
  
## Комбинирование Rate Limiter и Circuit Breaker  
  
В реальных системах оба паттерна могут использоваться вместе для защиты сервисов.  
  
```java
@RestController  
@RequestMapping("/api")  
public class ResilientController {
	private final CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults("apiCircuitBreaker");  
	private final RateLimiter rateLimiter = RateLimiter.ofDefaults("apiRateLimiter");  
	  
	@GetMapping("/protected")  
	public String protectedEndpoint() {  
		return circuitBreaker.executeSupplier(() ->  
			rateLimiter.executeSupplier(() -> "Request successfully handled"));  
	}  
}  
  
```
Здесь запросы сначала проходят через Rate Limiter, затем через Circuit Breaker, что помогает избежать перегрузки и отказов.  
  
## Заключение  
  
Паттерны Rate Limiter и Circuit Breaker играют важную роль в разработке надежных сервисов. Они позволяют:  
- Контролировать нагрузку на сервис (Rate Limiter).  
- Предотвращать лавинообразные отказы (Circuit Breaker).  
- Повышать устойчивость системы к перегрузкам и сбоям.  
  
Использование Spring Boot и Resilience4j делает их интеграцию удобной и гибкой. Важно правильно настраивать параметры этих механизмов в зависимости от нагрузки и критичности сервиса. 